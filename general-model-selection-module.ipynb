{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-10-15T12:03:49.356255Z","iopub.execute_input":"2023-10-15T12:03:49.356632Z","iopub.status.idle":"2023-10-15T12:03:49.459122Z","shell.execute_reply.started":"2023-10-15T12:03:49.356605Z","shell.execute_reply":"2023-10-15T12:03:49.458012Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"data = pd.read_csv('/kaggle/input/telecom-churn/telecom_churn.csv')\ndata","metadata":{"execution":{"iopub.status.busy":"2023-10-15T11:57:07.784147Z","iopub.execute_input":"2023-10-15T11:57:07.784706Z","iopub.status.idle":"2023-10-15T11:57:07.831209Z","shell.execute_reply.started":"2023-10-15T11:57:07.784660Z","shell.execute_reply":"2023-10-15T11:57:07.830176Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"      Churn  AccountWeeks  ContractRenewal  DataPlan  DataUsage  \\\n0         0           128                1         1       2.70   \n1         0           107                1         1       3.70   \n2         0           137                1         0       0.00   \n3         0            84                0         0       0.00   \n4         0            75                0         0       0.00   \n...     ...           ...              ...       ...        ...   \n3328      0           192                1         1       2.67   \n3329      0            68                1         0       0.34   \n3330      0            28                1         0       0.00   \n3331      0           184                0         0       0.00   \n3332      0            74                1         1       3.70   \n\n      CustServCalls  DayMins  DayCalls  MonthlyCharge  OverageFee  RoamMins  \n0                 1    265.1       110           89.0        9.87      10.0  \n1                 1    161.6       123           82.0        9.78      13.7  \n2                 0    243.4       114           52.0        6.06      12.2  \n3                 2    299.4        71           57.0        3.10       6.6  \n4                 3    166.7       113           41.0        7.42      10.1  \n...             ...      ...       ...            ...         ...       ...  \n3328              2    156.2        77           71.7       10.78       9.9  \n3329              3    231.1        57           56.4        7.67       9.6  \n3330              2    180.8       109           56.0       14.44      14.1  \n3331              2    213.8       105           50.0        7.98       5.0  \n3332              0    234.4       113          100.0       13.30      13.7  \n\n[3333 rows x 11 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Churn</th>\n      <th>AccountWeeks</th>\n      <th>ContractRenewal</th>\n      <th>DataPlan</th>\n      <th>DataUsage</th>\n      <th>CustServCalls</th>\n      <th>DayMins</th>\n      <th>DayCalls</th>\n      <th>MonthlyCharge</th>\n      <th>OverageFee</th>\n      <th>RoamMins</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>128</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2.70</td>\n      <td>1</td>\n      <td>265.1</td>\n      <td>110</td>\n      <td>89.0</td>\n      <td>9.87</td>\n      <td>10.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>107</td>\n      <td>1</td>\n      <td>1</td>\n      <td>3.70</td>\n      <td>1</td>\n      <td>161.6</td>\n      <td>123</td>\n      <td>82.0</td>\n      <td>9.78</td>\n      <td>13.7</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>137</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0.00</td>\n      <td>0</td>\n      <td>243.4</td>\n      <td>114</td>\n      <td>52.0</td>\n      <td>6.06</td>\n      <td>12.2</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>84</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.00</td>\n      <td>2</td>\n      <td>299.4</td>\n      <td>71</td>\n      <td>57.0</td>\n      <td>3.10</td>\n      <td>6.6</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>75</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.00</td>\n      <td>3</td>\n      <td>166.7</td>\n      <td>113</td>\n      <td>41.0</td>\n      <td>7.42</td>\n      <td>10.1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>3328</th>\n      <td>0</td>\n      <td>192</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2.67</td>\n      <td>2</td>\n      <td>156.2</td>\n      <td>77</td>\n      <td>71.7</td>\n      <td>10.78</td>\n      <td>9.9</td>\n    </tr>\n    <tr>\n      <th>3329</th>\n      <td>0</td>\n      <td>68</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0.34</td>\n      <td>3</td>\n      <td>231.1</td>\n      <td>57</td>\n      <td>56.4</td>\n      <td>7.67</td>\n      <td>9.6</td>\n    </tr>\n    <tr>\n      <th>3330</th>\n      <td>0</td>\n      <td>28</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0.00</td>\n      <td>2</td>\n      <td>180.8</td>\n      <td>109</td>\n      <td>56.0</td>\n      <td>14.44</td>\n      <td>14.1</td>\n    </tr>\n    <tr>\n      <th>3331</th>\n      <td>0</td>\n      <td>184</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.00</td>\n      <td>2</td>\n      <td>213.8</td>\n      <td>105</td>\n      <td>50.0</td>\n      <td>7.98</td>\n      <td>5.0</td>\n    </tr>\n    <tr>\n      <th>3332</th>\n      <td>0</td>\n      <td>74</td>\n      <td>1</td>\n      <td>1</td>\n      <td>3.70</td>\n      <td>0</td>\n      <td>234.4</td>\n      <td>113</td>\n      <td>100.0</td>\n      <td>13.30</td>\n      <td>13.7</td>\n    </tr>\n  </tbody>\n</table>\n<p>3333 rows Ã— 11 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"df = data.copy()","metadata":{"execution":{"iopub.status.busy":"2023-10-15T12:02:55.049192Z","iopub.execute_input":"2023-10-15T12:02:55.049681Z","iopub.status.idle":"2023-10-15T12:02:55.055242Z","shell.execute_reply.started":"2023-10-15T12:02:55.049647Z","shell.execute_reply":"2023-10-15T12:02:55.053998Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"X = df.drop(columns=['Churn'])\ny = df['Churn']","metadata":{"execution":{"iopub.status.busy":"2023-10-15T12:04:12.389532Z","iopub.execute_input":"2023-10-15T12:04:12.390731Z","iopub.status.idle":"2023-10-15T12:04:12.399634Z","shell.execute_reply.started":"2023-10-15T12:04:12.390682Z","shell.execute_reply":"2023-10-15T12:04:12.398339Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)","metadata":{"execution":{"iopub.status.busy":"2023-10-15T12:04:39.308441Z","iopub.execute_input":"2023-10-15T12:04:39.308802Z","iopub.status.idle":"2023-10-15T12:04:39.317945Z","shell.execute_reply.started":"2023-10-15T12:04:39.308776Z","shell.execute_reply":"2023-10-15T12:04:39.316447Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"___\n# Build a model selection module","metadata":{}},{"cell_type":"code","source":"# Classification models\n\nfrom lightgbm import LGBMClassifier\nfrom sklearn.linear_model import LogisticRegression, RidgeClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.svm import SVC\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, GradientBoostingClassifier\nfrom sklearn.linear_model import LogisticRegression","metadata":{"execution":{"iopub.status.busy":"2023-10-15T12:22:51.862815Z","iopub.execute_input":"2023-10-15T12:22:51.863182Z","iopub.status.idle":"2023-10-15T12:22:53.856770Z","shell.execute_reply.started":"2023-10-15T12:22:51.863156Z","shell.execute_reply":"2023-10-15T12:22:53.855501Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":"```python\n>> selecion_pipe = GMSModule(mode='binary_classification',\nmetrics=['f1-score', 'accuracy', 'precision'],\ninclude=[LinearRegression(),\nRidgeRegression()...]),\ndata=[X_train, X_test, y_train, y_test],\nverbose=True)\n\n>> selection_pipe.run()\n>> selection_pipe.name() # LGBMCLassifier\n>> selection_pipe.describe() # Linear Regression - 0.94...\n>> selection_pipe.evaluation() # F1-score: 0.94\n                               # Accuracy: 0.96...\n```","metadata":{}},{"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier","metadata":{"execution":{"iopub.status.busy":"2023-10-15T12:32:02.632264Z","iopub.execute_input":"2023-10-15T12:32:02.632651Z","iopub.status.idle":"2023-10-15T12:32:02.638420Z","shell.execute_reply.started":"2023-10-15T12:32:02.632622Z","shell.execute_reply":"2023-10-15T12:32:02.636989Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"## Import necessary libraries\n\nimport math\n# Scorings for 'classification'\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n# Scorings for 'regression'\nfrom sklearn.metrics import mean_absolute_error, mean_absolute_percentage_error, mean_squared_error, r2_score\n                            \n\n\n## Class\nclass GMSModule:\n    ## Initiate variables for work\n    def __init__(self, mode: str, include: list, data: list, metrics: list = ['accuracy']):\n        self.mode = mode\n        self.metrics = metrics\n        self.include = include\n        self.X_train, self.X_test, self.y_train, self.y_test = data\n\n    ## Get all models included into evaluation\n    def select_models(self):\n        return [i for i in self.include] \n\n    ## Evaluate models\n    def evaluate_models(self):\n        selected_models = self.select_models()\n        results = []\n\n        for model in selected_models:\n            model = model.fit(self.X_train, self.y_train)\n            y_pred = model.predict(self.X_test)\n            scores = {}\n\n            if self.mode == 'classification':\n                if 'accuracy' in self.metrics:\n                    scores['accuracy'] = accuracy_score(self.y_test, y_pred)\n                if 'precision' in self.metrics:\n                    scores['precision'] = precision_score(self.y_test, y_pred)\n                if 'recall' in self.metrics:\n                    scores['recall'] = recall_score(self.y_test, y_pred)\n                if 'f1-score' in self.metrics:\n                    scores['f1-score'] = f1_score(self.y_test, y_pred)\n                if 'roc-auc' in self.metrics:\n                    scores['roc-auc'] = roc_auc_score(self.y_test, y_pred)\n                results.append((model, scores))\n                \n            if self.mode == 'regression':\n                if 'mae' in self.metrics:\n                    scores['MAE (Mean Abs. Error)'] = mean_absolute_error(self.y_test, y_pred)\n                if 'mape' in self.metrics:\n                    scores['MAPE (Mean Abs. Percent. Error)'] = mean_absolute_percentage_error(self.y_test, y_pred)\n                if 'mse' in self.metrics:\n                    scores['MSE (Mean Squared Error)'] = mean_squared_error(self.y_test, y_pred)\n                if 'rmse' in self.metrics:\n                    scores['RMSE (Rooted Mean Squared Error)'] = math.sqrt(mean_squared_error(self.y_test, y_pred))\n                if 'r2-score' in self.metrics:\n                    scores['r2-score'] = r2_score(self.y_test, y_pred)\n                results.append((model, scores))\n\n        return results\n    \n    \n    ## Verbose descrition of each model\n    def describe(self):\n        result = self.evaluate_models()\n        \n        for model in result:\n            print(f\"{model[0]}: {model[1]}\")\n            \n            \n    ## Get info about the best model\n    def best_model(self, print_info: bool = False):\n        result = self.evaluate_models()\n        \n        # Initialize an empty dictionary\n        model_scores_dict = {}\n\n        # Iterate through the results and calculate the sum of scores\n        for model, scores in result:\n            model_name = model.__class__.__name__  # Get the model name as a string\n            score_sum = sum(scores.values())\n            model_scores_dict[model_name] = score_sum\n\n\n        # Find the key with the maximum value in the dictionary\n        best_model = max(model_scores_dict, key=model_scores_dict.get)\n\n        # Print the key of the model with the highest score\n        if print_info:\n            print(\"Model with the highest score:\", best_model)\n        else:\n            return best_model\n","metadata":{"execution":{"iopub.status.busy":"2023-10-15T13:25:21.721849Z","iopub.execute_input":"2023-10-15T13:25:21.722268Z","iopub.status.idle":"2023-10-15T13:25:21.738589Z","shell.execute_reply.started":"2023-10-15T13:25:21.722240Z","shell.execute_reply":"2023-10-15T13:25:21.736991Z"},"trusted":true},"execution_count":126,"outputs":[]},{"cell_type":"code","source":"GMSPipe = GMSModule(mode=\"classification\", metrics=['accuracy', 'f1-score'], include=[LogisticRegression(), RandomForestClassifier()], data=[X_train, X_test, y_train, y_test])\nGMSPipe.best_model()","metadata":{"execution":{"iopub.status.busy":"2023-10-15T13:25:21.895659Z","iopub.execute_input":"2023-10-15T13:25:21.896054Z","iopub.status.idle":"2023-10-15T13:25:22.570740Z","shell.execute_reply.started":"2023-10-15T13:25:21.896026Z","shell.execute_reply":"2023-10-15T13:25:22.569654Z"},"trusted":true},"execution_count":127,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  n_iter_i = _check_optimize_result(\n","output_type":"stream"},{"execution_count":127,"output_type":"execute_result","data":{"text/plain":"'RandomForestClassifier'"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}